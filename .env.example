# Telegram Bot
TELEGRAM_BOT_TOKEN=

# Ollama LLM
LLM_PROVIDER=ollama
LLM_MODEL=phi3:mini

# Для локального запуска вне Docker оставьте localhost:
# LLM_BASE_URL=http://localhost:11434
# Для запуска в Docker (мостовая сеть) используйте:
LLM_BASE_URL=http://localhost:11434
#  На Linux дополнительно убедитесь, что Ollama слушает 0.0.0.0 (см. README → Docker → Вариант B).

LLM_TEMPERATURE=0.6
LLM_MAX_NEW_TOKENS=800
