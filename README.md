# ProductCard AI — v1.0 (MVP)

Локальный генератор карточек товара (заголовок, краткое описание и пункты) через Ollama. Выход — строгий JSON. Есть CLI и Telegram‑бот с полным потоком: платформа → стиль → длина → ввод данных → генерация → экспорт/повтор. Хранение последних N генераций в SQLite, экспорт .txt/.csv, устойчивый JSON‑парсинг с ретраями.

## Установка
- Установите Ollama и загрузите модель:
  - `ollama pull phi3:mini`
  - тест: `ollama run phi3:mini "say ok"`
- Python 3.11+; установите зависимости: `pip install -r requirements.txt`
- Скопируйте `.env.example` в `.env` при необходимости и скорректируйте параметры LLM (по умолчанию подходят: `http://localhost:11434`, `phi3:mini`).

## Запуск CLI
Пример:

```
python -m cli "Беспроводная мышь Logitech M185" \
  --features "2.4 ГГц, тихие клики, до 12 мес работы" \
  --platform ozon --tone neutral
```

На выходе печатается JSON формата:

```
{
  "title": "...",
  "short_description": "...",
  "bullets": ["...", "..."]
}
```

## Запуск Telegram‑бота
1) Установить зависимости: `pip install -r requirements.txt`
2) Убедиться, что работает Ollama и модель загружена (`phi3:mini`).
3) Указать токен бота: скопировать `.env.example` в `.env` и заполнить `TELEGRAM_BOT_TOKEN`.
4) Запуск: `python -m bot.main`

Сценарий: `/start` → выбрать платформу → выбрать стиль → выбрать длину → одним сообщением отправить «название + характеристики» → получить сгенерированный текст. Можно экспортировать результат в .txt или .csv. Последние N генераций по пользователю сохраняются в SQLite.

## Тесты (для разработчиков)
- Установка dev‑зависимостей из `requirements.txt` (включает pytest).
- Запуск: `pytest -q`

## Документация
- Дорожная карта версий: `docs/ROADMAP.md` (текущий статус: v1.0)

## Развёртывание (Docker)
- Скопируйте `.env.example` в `.env` и укажите `TELEGRAM_BOT_TOKEN`.
- Убедитесь, что на хосте работает Ollama и загружена модель `phi3:mini`.
- Варианты запуска:
  - Linux (host network): `make build && make run-hostnet`
  - Универсальный: установите `LLM_BASE_URL=http://host.docker.internal:11434` в `.env`, затем `make build && make run`
- Логи контейнера: `make logs`
- Остановка: `make stop`

Примечание: на Linux для `make run` потребуется Docker 20.10+ (host-gateway). При необходимости настройте Ollama слушать `0.0.0.0`.

В следующих версиях планируется экспорт файлов и хранение последних генераций (см. ROADMAP).
