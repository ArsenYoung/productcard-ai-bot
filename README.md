# ProductCard AI — v1.1.2

Локальный генератор карточек товара (заголовок, краткое описание и пункты) через Ollama. Полный поток: платформа → стиль → длина → ввод данных → генерация → экспорт/повтор. Хранение последних N генераций в SQLite, устойчивый JSON‑парсинг с ретраями.

## Что нового в v1.1.2
- Исправлен падёж CI: добавлены недостающие файлы и обновлены тесты под устойчивую генерацию и локализацию.
- Небольшие правки README/бэйджа статуса.

## Что нового в v1.1.1
- GitHub Actions: автоматический прогон тестов на push/PR (workflow `Tests`).
- Небольшие правки тестов под локализацию и прогресс.

## Что нового в v1.1
- Отмена генерации во время выполнения (кнопка «Отмена»).
- Индикатор прогресса с процентом выполнения («Генерация… 0–100%»).
- Кэширование результатов (по входным данным) с TTL, ускоряет повторы.
- Тюнинг промптов под площадки (WB/Ozon) и русский стиль.
- Самовосстановление JSON‑ответов и фолбэки при сбоях модели.
- Локализация сообщений и экспорта (RU/EN). 

## Что нового в v1.0.1
- Русскоязычный системный и пользовательский промпт — модель пишет «родной» русский без кальки с английского.
- Жёсткий запрет на markdown/код‑блоки в ответе модели; никакого ```json в тексте.
- Локализованный вывод в чате Telegram (Площадка/Ввод/Характеристики/Заголовок/Описание/Пункты).
- Самовосстановление ответов: терпимый парсер JSON (извлечение из код‑блоков, удаление висячих запятых, regex‑восстановление ключей).
- Фолбэки: если модель вернула пустые поля — собираем описание и пункты из характеристик/названия.
- Не меняли экспортный формат: .txt/.csv и внутренний JSON — как раньше.

Рекомендация для более «ровного» стиля на RU: `LLM_TEMPERATURE=0.4` в `.env`.

## CI (GitHub Actions)
Статус: ![Tests](https://github.com/ArsenYoung/productcard-ai-bot/actions/workflows/tests.yml/badge.svg)

Запуск: Workflow `Tests` автоматически устанавливает зависимости и выполняет `pytest -q` на Python 3.11.

Все операции и настройка выполняются через `make`.

## Быстрый старт
- Справка по целям: `make help`
- Проверка окружения: `make doctor`

## Настройка окружения
- Создать `.env` из примера: `make env-init`
- Установить/обновить переменную в `.env`: `make env-set KEY=TELEGRAM_BOT_TOKEN VALUE=xxxxxxxx`
- Показать текущие переменные (безопасно): `make env-print`
- Скачать модель Ollama (по умолчанию `phi3:mini`): `make ollama-pull` (можно переопределить `OLLAMA_MODEL=...`)

## Локальная разработка
- Установить зависимости в виртуальное окружение: `make install`
- Запуск CLI:
  - Вариант 1 (аргументы одной строкой): `make cli ARGS="\
    \"Беспроводная мышь Logitech M185\" --features \"2.4 ГГц, тихие клики\" --platform ozon --tone neutral"`
  - Вариант 2 (переменные): `make cli TEXT="Беспроводная мышь Logitech M185" FEATURES="2.4 ГГц, тихие клики" PLATFORM=ozon TONE=neutral`
- Запуск Telegram‑бота локально: `make bot` (нужен `TELEGRAM_BOT_TOKEN` и доступный Ollama)
- Тесты: `make test`

Пример JSON, возвращаемый CLI:

```
{
  "title": "...",
  "short_description": "...",
  "bullets": ["...", "..."]
}
```

## Развёртывание (Docker)
- Подготовка `.env`: `make env-init`, заполните `TELEGRAM_BOT_TOKEN` и проверьте `LLM_BASE_URL=http://localhost:11434`.
- Запуск (единый вариант, Linux host network): `make up`
- Логи контейнера: `make logs`
- Остановка/удаление контейнера: `make down`
- Список контейнеров: `make ps`

Примечание: контейнер запускается с `--network host` (Linux). Убедитесь, что Ollama слушает `localhost:11434` на хосте.

## Полезно
- Проверка окружения и зависимостей: `make doctor`
- Переопределяемые переменные: `IMAGE_NAME`, `TAG`, `CONTAINER_NAME`, `ENV_FILE`, `VENV_DIR`, `OLLAMA_MODEL`.

## Документация
- Дорожная карта версий: `docs/ROADMAP.md` (текущий статус: v1.0)
